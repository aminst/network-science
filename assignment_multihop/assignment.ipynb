{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment â€” Multi-hop Reasoning on Knowledge graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowledge graph embedding allows predicting missed links in the graph. However, it does not allow to answer of complex logical queries.\n",
    "\n",
    "For example, one can want to answer `Where did Canadian citizens with Turing Award graduate?`. Such question can be decomposed into several smaller questions and construct DAG (directed acyclic graph) of logical operations.\n",
    "\n",
    "\n",
    "![test](https://github.com/netspractice/network-science/raw/main/assignment_multihop/model.png)\n",
    "\n",
    "_reference: http://snap.stanford.edu/query2box/_\n",
    "\n",
    "We will use implementations of models from https://github.com/snap-stanford/KGReasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchkge import KnowledgeGraph\n",
    "from torchkge.utils import Trainer\n",
    "from torchkge.models.bilinear import RESCALModel\n",
    "from torchkge.utils import MarginLoss\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zlib import adler32\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Beam-search with RESCAL (1 point)\n",
    "\n",
    "Beam-search is a technique of generating most probable sequences.\n",
    "\n",
    "![image.png](https://github.com/netspractice/network-science/blob/main/assignment_multihop/beamsearch.png?raw=true)\n",
    "\n",
    "It works as follows:\n",
    "1. Start from some root (`<START>` token on image)\n",
    "2. Predict subsequent tokens\n",
    "3. Select `k` most probable subsequences from generated\n",
    "4. Repeat the procedure\n",
    "\n",
    "In the current task, we will apply it to the query represented in the sequential form.\n",
    "\n",
    "We will work with the queries that can be represented in conjunctive normal form. For example, we have a query `What country was replaced by Canada neighbours`. `Canada neighbors` can be found by prediction tail `t` for query `h = \"Canada\"`, `r = \"shares border with\"`. And `What country was replaced by` could be represented as a tail for query `h = t`, `r = \"replaces\"`.\n",
    "\n",
    "So our query can be decomposed into two smaller ones.\n",
    "\n",
    "Let us download the dataset from the previous seminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/netspractice/network-science/main/datasets/countries_edges.tsv'\n",
    "open('countries_edges.tsv', 'wb').write(requests.get(url).content)\n",
    "url = 'https://raw.githubusercontent.com/netspractice/network-science/main/datasets/countries_entities.tsv'\n",
    "open('countries_entities.tsv', 'wb').write(requests.get(url).content)\n",
    "url = 'https://raw.githubusercontent.com/netspractice/network-science/main/datasets/countries_relations.tsv'\n",
    "open('countries_relations.tsv', 'wb').write(requests.get(url).content);\n",
    "\n",
    "\n",
    "edges = pd.read_csv('countries_edges.tsv', sep='\t').values\n",
    "entity_labels = pd.read_csv('countries_entities.tsv', sep='\t', index_col=0).label.values\n",
    "relation_labels = pd.read_csv('countries_relations.tsv', sep='\t', index_col=0).label.values\n",
    "\n",
    "edges_labeled = np.stack([entity_labels[edges[:, 0]], \n",
    "                          entity_labels[edges[:, 1]], \n",
    "                          relation_labels[edges[:, 2]]], axis=1)\n",
    "\n",
    "df = pd.DataFrame(edges_labeled, columns=['h', 't', 'r'])[['h', 'r', 't']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we need to check the answer in the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = set(df[(df.h == 'Canada') & (df.r == \"shares border with\")].t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81c3b45bab699df74cc4bf4d4c87100b",
     "grade": false,
     "grade_id": "cell-3c9f642cb829f305",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_replaces(df):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93aaa59ec96db1a63cd2920dcd01c25d",
     "grade": true,
     "grade_id": "cell-25635e4d2ac7c6c5",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "el = find_replaces(df).pop()\n",
    "assert adler32(el.encode()) == 2730560188\n",
    "print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find an answer in our dataset, but for complex queries or incomplete graphs, such a task could be very hard. So we can work with knowledge graph embedding models to solve it.\n",
    "\n",
    "Firstly, let us initialize the knowledge graph dataset from torchkge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = KnowledgeGraph(pd.DataFrame(edges_labeled, columns=['from', 'to', 'rel']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we need to train the fine embedding model. We will use `RESCALModel` from torchkge. Similarly to the TransE model from the previous seminar, it learns two embedding tensors. However, instead of embed relations, it learns the projection matrix for each relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RESCALModel(128, kg.n_ent, kg.n_rel)\n",
    "criterion = MarginLoss(margin=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model, criterion, kg, n_epochs=250, \n",
    "    batch_size=2048, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model trained, we need to find the top k most similar tails to our head and relation.\n",
    "\n",
    "You need to define the `find_most_similar` function that takes our trained model, knowledge graph, head and relation from a query in string form and the number of most similar items to return.\n",
    "\n",
    "It works as follows:\n",
    "\n",
    "1. Extract embeddings from the model using `get_embeddings` method\n",
    "2. Extract vector for head\n",
    "3. Extract matrix for relation\n",
    "4. Calculate predicted embedding for tail via torch.matmull over head vector and relation matrix\n",
    "5. Normalize predicted vector\n",
    "6. Calculate cosine similarity between predicted embedding and each entity from entity embedding matrix (normalize dot product + 1 / 2)\n",
    "7. Return np.array with indices of the top k most similar entities and np.array with corresponding values sorted in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c16f73b5bc303a2d3ce80324d4245f2",
     "grade": false,
     "grade_id": "cell-e4e87013d896c76c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_most_similar(model, kg, head, relation, k):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c21f281c4d0df9e791d3a8321218d323",
     "grade": true,
     "grade_id": "cell-8254be5ac8f94775",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ids, sims = find_most_similar(model, kg, \"Canada\", \"shares border with\", 5)\n",
    "assert len(ids) == 5\n",
    "assert ((sims[:-1] - sims[1:]) >= 0).mean() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try to answer our query in two steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "810bff57444d2e3ce4f7350fcaf47447",
     "grade": true,
     "grade_id": "cell-bc16ae4353cb8eef",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 1\n",
    "ids, sims = find_most_similar(model, kg, \"Canada\", \"shares border with\", 5)\n",
    "\n",
    "# 2\n",
    "ix2ent = {j: i for i, j in kg.ent2ix.items()}\n",
    "results = []\n",
    "for i in ids:\n",
    "    idx, s = find_most_similar(model, kg, ix2ent[i], \"replaces\", 5)\n",
    "    score_matrix = np.outer(sims, s).flatten()\n",
    "    topk = score_matrix.argsort()[-5:]\n",
    "    results.extend(zip(ids[topk // 5], idx[topk % 5], score_matrix[topk]))\n",
    "results_topk = sorted(results, key=lambda x: x[2])[-5:]\n",
    "results_topk_entities = [ix2ent[j] for _, j, _ in results_topk]\n",
    "\n",
    "assert 2730560188 in [adler32(i.encode()) for i in results_topk_entities]\n",
    "print('\\n'.join(results_topk_entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. [Graph query embedding](https://arxiv.org/abs/1806.01445) (2 points)\n",
    "\n",
    "In the previous task we use the several projection steps. It is a analogue of existential quantification in the vector space.\n",
    "\n",
    "Graph Query Embedding also allow to handle conjunction between different statements. For example, we may want to answer question `What country Russia and Canada share border with?`.\n",
    "\n",
    "This statement could be decomposed to the statement. `Russia shares border with` & `Canada shares border with`.\n",
    "\n",
    "The GQE models the projection using translation operator (similarly to TransE) and [DeepSets](https://arxiv.org/abs/1703.06114) to model conjunction. The intersection operator works in several steps:\n",
    "1. We pass individual element embeddings through the feed-forward neural network.\n",
    "2. We aggregate the result of model inference using a symmetric operator (e.g. mean, sum).\n",
    "3. Transform it using a projection matrix.\n",
    "\n",
    "Let us download the realized models from https://github.com/snap-stanford/KGReasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/snap-stanford/KGReasoning/main/models.py'\n",
    "with open(\"models.py\", \"wb\") as f:\n",
    "    f.write(requests.get(url).content)\n",
    "    \n",
    "url = 'https://raw.githubusercontent.com/snap-stanford/KGReasoning/main/dataloader.py'\n",
    "with open(\"dataloader.py\", \"wb\") as f:\n",
    "    f.write(requests.get(url).content)\n",
    "    \n",
    "url = 'https://raw.githubusercontent.com/snap-stanford/KGReasoning/main/util.py'\n",
    "with open(\"util.py\", \"wb\") as f:\n",
    "    f.write(requests.get(url).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we need to define what types of queries we will prefer to handle.\n",
    "\n",
    "1. `1p` is one projection (both models)\n",
    "2. `2p` is two sequential projections (both models)\n",
    "3. `2u-DNF` is a disjunctive normal form, i.e. union (disjunction) between two `1p` queries (Q2B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_name_dict = {\n",
    "    ('e',('r',)): '1p', \n",
    "    ('e', ('r', 'r')): '2p',\n",
    "    (('e', ('r',)), ('e', ('r',))): '2i',\n",
    "    (('e', ('r',)), ('e', ('r',)), ('u',)): '2u-DNF',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before model training, we need to generate datasets for it.\n",
    "\n",
    "You need to implement two functions, `generate_queries` and `generete_queries_conjunction`.\n",
    "\n",
    "The first one generates one- and two-hop queries and answers. It takes df with hrt triplets, mapping from text entity to ids (`kg.ent2ix`), mapping from text relation to ids (`kg.rel2ix`). And it should return the list with triplets in the form of query type and the mapping of answers. Answers are constructed as a python dictionary where keys are queries and value is a set of possible tails to answer the given query.\n",
    "\n",
    "E.g. if we have a query of type `1p` the sample should look like `(187, (41,))`. Similarly, for `2i` query: `(187, (41,), (1342, (41,)))`.\n",
    "\n",
    "The answer for this queries should look like:\n",
    "\n",
    "```\n",
    "{\n",
    "    (187, (41,)): {345, 588, 1666},\n",
    "    (187, (41,), (1342, (41,))): {1666}\n",
    "}\n",
    "```\n",
    "\n",
    "Firstly, you need to convert heads, relations and tails by corresponding ids.\n",
    "\n",
    "Then, you need to calculate one-hop queries. One-hop queries could be calculated by group by over data frame (`df.groupby(['h','r']).t.agg(set)`)\n",
    "\n",
    "Finally, you need to find two-hop relations. We can join the data frame on itself left_on `t` and right_on `h`. Now, the data frame should be grouped by `h_x`, `r_x` and `r_y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66e00ef41af9ef60610a82ec2a07dd58",
     "grade": false,
     "grade_id": "cell-15c6431858cc2ec5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_queries(df, ent2id, rel2id):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbddc9b594c31cbe6bd694eab1d042f8",
     "grade": true,
     "grade_id": "cell-da7d7a90198e515d",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_queries, train_answers = generate_queries(df, kg.ent2ix, kg.rel2ix)\n",
    "assert train_queries[0][1] in [(('e', ('r',))), ('e', ('r', 'r'))]\n",
    "assert ((187, (41,)), ('e', ('r',))) in train_queries\n",
    "assert adler32(' '.join([str(i) for i in sorted(list(train_answers[(187, (41,))]))]).encode()) == 252052053"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we want to generate some intersection (conjunction) examples of type `2i` with `generate_queries_conjunction`.\n",
    "\n",
    "Intersection result of two projection relations could be achieved by joining the data frame with itself on `t` column because intersection means coincidental result.\n",
    "\n",
    "`generate_queries_conjunction` works similarly to `generate_queries` but should find intersection queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2a6ccd0fbf38fce1ec11a894e0e80ba",
     "grade": false,
     "grade_id": "cell-e41acdf75ba8a0dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_queries_conjunction(df, ent2id, rel2id):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19aa9bdbba074ef959da138860d60c6a",
     "grade": true,
     "grade_id": "cell-9b822680cc0b3534",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_queries_conj, train_answers_conj = generate_queries_conjunction(df, kg.ent2ix, kg.rel2ix)\n",
    "assert train_queries_conj[0][1] == (('e', ('r',)), ('e', ('r',)))\n",
    "assert (((1808, (6,)), (1084, (12,))), (('e', ('r',)), ('e', ('r',)))) in train_queries_conj\n",
    "assert train_answers_conj[((1808, (6,)), (1084, (12,)))] == {1666}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can merge both train samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries.extend(train_queries_conj)\n",
    "train_answers.update(train_answers_conj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to instantiate the GQE model using the `KGReasoning` wrapper. The `geo` argument defines what model to use: `vec` is a GQE, `box` is a Query2Box, `betae` is a BetaE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqe_model = models.KGReasoning(\n",
    "    nentity=kg.n_ent,\n",
    "    nrelation=kg.n_rel,\n",
    "    hidden_dim=800,\n",
    "    gamma=24,\n",
    "    geo=\"vec\",\n",
    "    use_cuda=False,\n",
    "    box_mode=None,\n",
    "    beta_mode=None,\n",
    "    test_batch_size=128,\n",
    "    query_name_dict=query_name_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer to train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, cqe_model.parameters()), \n",
    "    lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataloader import TestDataset, TrainDataset, SingledirectionalOneShotIterator\n",
    "\n",
    "train_path_iterator = SingledirectionalOneShotIterator(DataLoader(\n",
    "    TrainDataset(train_queries, kg.n_ent, kg.n_rel, 128, train_answers),\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=TrainDataset.collate_fn\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us mock-up CLI arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    print_on_screen = True\n",
    "    cuda = False\n",
    "    test_batch_size = 1\n",
    "    test_log_steps = 10\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trange(50):\n",
    "    cqe_model.train_step(cqe_model, optimizer, train_path_iterator, args,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict results, we need to define the `predict_kg_reasoning` function.\n",
    "\n",
    "The input is our trained model, torchkge knowledge graph, flatten query and its type.\n",
    "\n",
    "Flatten query is a flat list with ids, without query_type structure, e.g. `[1342, 41, 187, 41]`\n",
    "\n",
    "We will use the native model.forward function. It takes several arguments: positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict. The positive_sample and subsampling_weight is None.\n",
    "\n",
    "The negative sample is constructed as array of all entity ids with the shape `(1, number of entities)`.\n",
    "\n",
    "\n",
    "After, you need to construct batch_queries_dict -- a mapping from query type to query wrapped with torch.tensor of shape `(1, len(flatten_query))`.\n",
    "\n",
    "Then, you need to construct batch_idxs_dict -- a mapping from query_type to indices of corresponding queries. Here we have only one index so that it will be a `{query_type: [0]}`.\n",
    "\n",
    "Now, you can pass it to the `model.forward` function and receive `positive_logit, negative_logit, subsampling_weight, batch_ids`. However, we are only interested in the `negative_logit`.\n",
    "\n",
    "Negative logit is our score of how close each entity is to our answer. To choose the best entity ids, we need to argsort our negative_logit and take top k.\n",
    "\n",
    "Finally, you need to convert entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f46574a0272f7767ef8ba7206fea840",
     "grade": false,
     "grade_id": "cell-d336ee5ca59b24c5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_kg_reasoning(model, kg, flatten_query, query_type, k=5, ix2ent=ix2ent):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8bf2a6f3ac81b4b17dced37e8c36e21",
     "grade": true,
     "grade_id": "cell-81ef8f936aa68ec3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans = predict_kg_reasoning(cqe_model, kg, [kg.ent2ix['Russia'], kg.rel2ix['shares border with'], kg.ent2ix['Canada'], kg.rel2ix['shares border with']], (('e', ('r', )), ('e', ('r', ))))\n",
    "assert 1847527621 in [adler32(i.encode()) for i in ans]\n",
    "print('\\n'.join(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. [Query2Box](http://snap.stanford.edu/query2box/) (7 points)\n",
    "\n",
    "Query2Box additionally allow to model union (disjunction) queries.\n",
    "\n",
    "\n",
    "The general idea of Query2Box is to model sets as boxes. If an entity is in the set, then the corresponding embedding should lie inside the query box. The box is defined by the vector of centre and offset.\n",
    "\n",
    "The projection (existential operator) works similarly to the translation models: the model sums the centres and offsets.\n",
    "The intersection of the boxes could be found by performing attention over box queries. Offsets are calculated using DeepSets over the boxes and are shrunk with the sigmoid function.\n",
    "\n",
    "A simple geometric union of the boxes could be a bad idea because query boxes could lie in different places of our space. So, before doing union, the authors propose transforming our query to the disjunctive normal form (DNF).\n",
    "It allows to perform all box logic with projection and intersection operators and, finally, found the best entities close to one of the resulting boxes.\n",
    "\n",
    "![test](https://github.com/netspractice/network-science/blob/main/assignment_multihop/query2box.png?raw=true)\n",
    "\n",
    "\n",
    "Before we train the model, we need to generate the disjunctive examples to it.\n",
    "\n",
    "We will generate union pairs only for relation type `shares border with`.\n",
    "`generate_queries_disjunction` takes the data frame with triplets, entity to index converter, relation to index converter, number of elements in subsample and random_state for sampling.\n",
    "\n",
    "1. Generate one-hop queries\n",
    "2. Generate two samples from step 1 using `df.sample(n, random_state=random_state)`\n",
    "3. zip one-hop queries and construct union query (e.g. `((187, (41, )), (1071, (41, )), (-1,))`)\n",
    "4. construct answers as unions of answers for one-hop queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44bc343a09394d8ba5d088e4163e8910",
     "grade": false,
     "grade_id": "cell-847174c7a86df6ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_queries_disjunction(df, ent2id, rel2id, n, random_state=0):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries_dis = []\n",
    "train_answers_dis = {}\n",
    "for i in trange(500):\n",
    "    tq, ta = generate_queries_disjunction(df, kg.ent2ix, kg.rel2ix, 300, random_state=2 * i)\n",
    "    train_queries_dis.extend(tq)\n",
    "    train_answers_dis.update(ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c755cf47959734702104a04674d02920",
     "grade": true,
     "grade_id": "cell-f56796364508c056",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert train_queries_dis[0][1] == (('e', ('r',)), ('e', ('r',)), ('u',))\n",
    "assert (((129, (41,)), (1706, (41,)), (-1,)), (('e', ('r',)), ('e', ('r',)), ('u',))) in train_queries_dis\n",
    "assert sum(train_answers_dis[(((129, (41,)), (1706, (41,)), (-1,)))]) == 2267"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize model, optimizer and train iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2b_model = models.KGReasoning(\n",
    "    nentity=kg.n_ent,\n",
    "    nrelation=kg.n_rel,\n",
    "    hidden_dim=800,\n",
    "    gamma=24,\n",
    "    geo=\"box\",\n",
    "    use_cuda=False,\n",
    "    box_mode=('relu', 0.05),\n",
    "    beta_mode=None,\n",
    "    test_batch_size=128,\n",
    "    query_name_dict=query_name_dict\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, q2b_model.parameters()), \n",
    "    lr=0.01\n",
    ")\n",
    "\n",
    "train_path_iterator = SingledirectionalOneShotIterator(DataLoader(\n",
    "    TrainDataset(train_queries_dis, kg.n_ent, kg.n_rel, 128, train_answers_dis),\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=TrainDataset.collate_fn\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will try to answer the question `What countries share a border with Canada or Mexico?`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df[(df.h == 'Mexico') & (df.r == 'shares border with')].append(df[(df.h == 'Canada') & (df.r == 'shares border with')]).t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trange(50):\n",
    "    q2b_model.train_step(q2b_model, optimizer, train_path_iterator, args,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad575febb54adb3f0739de4f4f7dfc1a",
     "grade": true,
     "grade_id": "cell-f721f2b1aac81494",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans = predict_kg_reasoning(\n",
    "    q2b_model,\n",
    "    kg,\n",
    "    [kg.ent2ix['Canada'], kg.rel2ix['shares border with'], kg.ent2ix['Mexico'], kg.rel2ix['shares border with'], -1],\n",
    "    (('e', ('r',)), ('e', ('r',)), ('u',)), k=10, ix2ent=ix2ent)\n",
    "hashed = [adler32(i.encode()) for i in ans]\n",
    "assert 1847527621 in hashed\n",
    "assert 1897990456 in hashed\n",
    "assert 131007068 in hashed\n",
    "assert 295175058 in hashed\n",
    "assert 292684689 in hashed\n",
    "print('\\n'.join(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
